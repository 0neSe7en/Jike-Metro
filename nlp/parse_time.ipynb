{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 1000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m, locale='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0点43分32秒', 'ABS>00:43:32'),\n",
       " ('52秒后', '+52S        '),\n",
       " ('下午11:57:47', 'ABS>23:57:47'),\n",
       " ('上午12点50分32秒', 'ABS>00:50:32'),\n",
       " ('再过2分钟', '+2M         '),\n",
       " ('周六7点55分36秒', 'TW6>07:55:36'),\n",
       " ('下午5点1分', 'ABS>17:01:48'),\n",
       " ('33小时以后', '+33H        '),\n",
       " ('下午8点24分55秒', 'ABS>20:24:55'),\n",
       " ('5秒以后', '+5S         ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (1000, 30)\n",
      "Y.shape (1000, 12)\n",
      "Xoh.shape (1000, 30, 41)\n",
      "Yoh.shape (1000, 12, 23)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 12\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "print('Xoh.shape', Xoh.shape)\n",
    "print('Yoh.shape', Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source time: 0点43分32秒\n",
      "Target time: ABS>00:43:32\n",
      "\n",
      "Source after preprocessing (indices): [ 0 34  4  3 22  3  2 35 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40]\n",
      "Target after preprocessing (indices): [14 15 20 13  2  2 12  6  5 12  5  4]\n",
      "\n",
      "Source after preprocessing (one-hot): [[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "Target after preprocessing (one-hot): [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print('Source time:', dataset[index][0])\n",
    "print('Target time:', dataset[index][1])\n",
    "print()\n",
    "print('Source after preprocessing (indices):', X[index])\n",
    "print('Target after preprocessing (indices):', Y[index])\n",
    "print()\n",
    "print('Source after preprocessing (one-hot):', Xoh[index])\n",
    "print('Target after preprocessing (one-hot):', Yoh[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeator = RepeatVector(Tx, name='rep')\n",
    "concatenator = Concatenate(axis=-1, name='conc')\n",
    "densor = Dense(1, activation='relu', name='densor')\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes=1, name='doter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    e = densor(concat)\n",
    "    alphas = activator(e)\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 64\n",
    "n_s = 128\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True, name='post_activation')\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(a, s)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        out = output_layer(s)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs, name='TranslationModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 41)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 128)      54272       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rep (RepeatVector)              (None, 30, 128)      0           s0[0][0]                         \n",
      "                                                                 post_activation[0][0]            \n",
      "                                                                 post_activation[1][0]            \n",
      "                                                                 post_activation[2][0]            \n",
      "                                                                 post_activation[3][0]            \n",
      "                                                                 post_activation[4][0]            \n",
      "                                                                 post_activation[5][0]            \n",
      "                                                                 post_activation[6][0]            \n",
      "                                                                 post_activation[7][0]            \n",
      "                                                                 post_activation[8][0]            \n",
      "                                                                 post_activation[9][0]            \n",
      "                                                                 post_activation[10][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conc (Concatenate)              (None, 30, 256)      0           bidirectional_1[0][0]            \n",
      "                                                                 rep[0][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[1][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[2][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[3][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[4][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[5][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[6][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[7][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[8][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[9][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[10][0]                       \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[11][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "densor (Dense)                  (None, 30, 1)        257         conc[0][0]                       \n",
      "                                                                 conc[1][0]                       \n",
      "                                                                 conc[2][0]                       \n",
      "                                                                 conc[3][0]                       \n",
      "                                                                 conc[4][0]                       \n",
      "                                                                 conc[5][0]                       \n",
      "                                                                 conc[6][0]                       \n",
      "                                                                 conc[7][0]                       \n",
      "                                                                 conc[8][0]                       \n",
      "                                                                 conc[9][0]                       \n",
      "                                                                 conc[10][0]                      \n",
      "                                                                 conc[11][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           densor[0][0]                     \n",
      "                                                                 densor[1][0]                     \n",
      "                                                                 densor[2][0]                     \n",
      "                                                                 densor[3][0]                     \n",
      "                                                                 densor[4][0]                     \n",
      "                                                                 densor[5][0]                     \n",
      "                                                                 densor[6][0]                     \n",
      "                                                                 densor[7][0]                     \n",
      "                                                                 densor[8][0]                     \n",
      "                                                                 densor[9][0]                     \n",
      "                                                                 densor[10][0]                    \n",
      "                                                                 densor[11][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "doter (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "post_activation (LSTM)          [(None, 128), (None, 131584      doter[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 doter[1][0]                      \n",
      "                                                                 post_activation[0][0]            \n",
      "                                                                 post_activation[0][2]            \n",
      "                                                                 doter[2][0]                      \n",
      "                                                                 post_activation[1][0]            \n",
      "                                                                 post_activation[1][2]            \n",
      "                                                                 doter[3][0]                      \n",
      "                                                                 post_activation[2][0]            \n",
      "                                                                 post_activation[2][2]            \n",
      "                                                                 doter[4][0]                      \n",
      "                                                                 post_activation[3][0]            \n",
      "                                                                 post_activation[3][2]            \n",
      "                                                                 doter[5][0]                      \n",
      "                                                                 post_activation[4][0]            \n",
      "                                                                 post_activation[4][2]            \n",
      "                                                                 doter[6][0]                      \n",
      "                                                                 post_activation[5][0]            \n",
      "                                                                 post_activation[5][2]            \n",
      "                                                                 doter[7][0]                      \n",
      "                                                                 post_activation[6][0]            \n",
      "                                                                 post_activation[6][2]            \n",
      "                                                                 doter[8][0]                      \n",
      "                                                                 post_activation[7][0]            \n",
      "                                                                 post_activation[7][2]            \n",
      "                                                                 doter[9][0]                      \n",
      "                                                                 post_activation[8][0]            \n",
      "                                                                 post_activation[8][2]            \n",
      "                                                                 doter[10][0]                     \n",
      "                                                                 post_activation[9][0]            \n",
      "                                                                 post_activation[9][2]            \n",
      "                                                                 doter[11][0]                     \n",
      "                                                                 post_activation[10][0]           \n",
      "                                                                 post_activation[10][2]           \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 23)           2967        post_activation[0][0]            \n",
      "                                                                 post_activation[1][0]            \n",
      "                                                                 post_activation[2][0]            \n",
      "                                                                 post_activation[3][0]            \n",
      "                                                                 post_activation[4][0]            \n",
      "                                                                 post_activation[5][0]            \n",
      "                                                                 post_activation[6][0]            \n",
      "                                                                 post_activation[7][0]            \n",
      "                                                                 post_activation[8][0]            \n",
      "                                                                 post_activation[9][0]            \n",
      "                                                                 post_activation[10][0]           \n",
      "                                                                 post_activation[11][0]           \n",
      "==================================================================================================\n",
      "Total params: 189,080\n",
      "Trainable params: 189,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 32.8452 - output_loss: 2.8419 - output_acc: 0.0000e+00 - output_acc_1: 0.0070 - output_acc_2: 0.0070 - output_acc_3: 0.0330 - output_acc_4: 0.2640 - output_acc_5: 0.2080 - output_acc_6: 0.3900 - output_acc_7: 0.1800 - output_acc_8: 0.1820 - output_acc_9: 0.3980 - output_acc_10: 0.1870 - output_acc_11: 0.1790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 29.6713 - output_loss: 2.5387 - output_acc: 1.0000e-03 - output_acc_1: 0.0000e+00 - output_acc_2: 0.0000e+00 - output_acc_3: 0.2270 - output_acc_4: 0.3080 - output_acc_5: 0.3080 - output_acc_6: 0.4270 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 0.3860 - output_acc_10: 0.3080 - output_acc_11: 0.3080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 25.8524 - output_loss: 2.1301 - output_acc: 0.0000e+00 - output_acc_1: 0.0000e+00 - output_acc_2: 0.0000e+00 - output_acc_3: 0.6300 - output_acc_4: 0.3320 - output_acc_5: 0.3300 - output_acc_6: 0.8350 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 0.7920 - output_acc_10: 0.3080 - output_acc_11: 0.3080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 22.1157 - output_loss: 1.8436 - output_acc: 0.1000 - output_acc_1: 0.1700 - output_acc_2: 0.0000e+00 - output_acc_3: 0.7360 - output_acc_4: 0.4450 - output_acc_5: 0.3110 - output_acc_6: 1.0000 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 1.0000 - output_acc_10: 0.3080 - output_acc_11: 0.3080\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 20.3269 - output_loss: 1.8421 - output_acc: 0.4090 - output_acc_1: 0.3380 - output_acc_2: 0.0330 - output_acc_3: 0.7360 - output_acc_4: 0.5700 - output_acc_5: 0.3360 - output_acc_6: 1.0000 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 1.0000 - output_acc_10: 0.3080 - output_acc_11: 0.3080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 18.7070 - output_loss: 1.7956 - output_acc: 0.5820 - output_acc_1: 0.3380 - output_acc_2: 0.2810 - output_acc_3: 0.7370 - output_acc_4: 0.5900 - output_acc_5: 0.3440 - output_acc_6: 1.0000 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 1.0000 - output_acc_10: 0.3080 - output_acc_11: 0.3080\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 17.1616 - output_loss: 1.7825 - output_acc: 0.7090 - output_acc_1: 0.3970 - output_acc_2: 0.3020 - output_acc_3: 0.7610 - output_acc_4: 0.5830 - output_acc_5: 0.3910 - output_acc_6: 0.9990 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 0.9990 - output_acc_10: 0.3080 - output_acc_11: 0.3080\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 15.9266 - output_loss: 1.7512 - output_acc: 0.7050 - output_acc_1: 0.4820 - output_acc_2: 0.3190 - output_acc_3: 0.7770 - output_acc_4: 0.5860 - output_acc_5: 0.3830 - output_acc_6: 1.0000 - output_acc_7: 0.3080 - output_acc_8: 0.3080 - output_acc_9: 1.0000 - output_acc_10: 0.3080 - output_acc_11: 0.3250\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 14.8525 - output_loss: 1.7332 - output_acc: 0.7110 - output_acc_1: 0.6200 - output_acc_2: 0.3700 - output_acc_3: 0.7620 - output_acc_4: 0.5790 - output_acc_5: 0.4170 - output_acc_6: 1.0000 - output_acc_7: 0.4090 - output_acc_8: 0.3080 - output_acc_9: 1.0000 - output_acc_10: 0.3080 - output_acc_11: 0.3330\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 13.7934 - output_loss: 1.6781 - output_acc: 0.7890 - output_acc_1: 0.6530 - output_acc_2: 0.3860 - output_acc_3: 0.8080 - output_acc_4: 0.5990 - output_acc_5: 0.3990 - output_acc_6: 1.0000 - output_acc_7: 0.4270 - output_acc_8: 0.3090 - output_acc_9: 1.0000 - output_acc_10: 0.3090 - output_acc_11: 0.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fc23e87b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_1 to have 3 dimensions, but got array with shape (41, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-32bbbf34b22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring2int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minv_machine_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_1 to have 3 dimensions, but got array with shape (41, 30)"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['明天下午3:04', '这周六10:20', '上午9点10分', '10分钟以后']\n",
    "\n",
    "for example in EXAMPLES:    \n",
    "    source = string2int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
