{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/I321267/anaconda3/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 100000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m, locale='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0点43分53秒', 'ABS>00:43:53'),\n",
       " ('52秒后', '+52S        '),\n",
       " ('下午11:58:08', 'ABS>23:58:08'),\n",
       " ('上午12点50分53秒', 'ABS>00:50:53'),\n",
       " ('再过2分钟', '+2M         '),\n",
       " ('周六7点55分57秒', 'TW6>07:55:57'),\n",
       " ('下午5点2分', 'ABS>17:02:09'),\n",
       " ('33小时以后', '+33H        '),\n",
       " ('下午8点25分16秒', 'ABS>20:25:16'),\n",
       " ('5秒以后', '+5S         ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (100000, 30)\n",
      "Y.shape (100000, 12)\n",
      "Xoh.shape (100000, 30, 41)\n",
      "Yoh.shape (100000, 12, 23)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 12\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "print('Xoh.shape', Xoh.shape)\n",
    "print('Yoh.shape', Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source time: 0点43分53秒\n",
      "Target time: ABS>00:43:53\n",
      "\n",
      "Source after preprocessing (indices): [ 0 34  4  3 22  5  3 35 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40]\n",
      "Target after preprocessing (indices): [14 15 20 13  2  2 12  6  5 12  7  5]\n",
      "\n",
      "Source after preprocessing (one-hot): [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print('Source time:', dataset[index][0])\n",
    "print('Target time:', dataset[index][1])\n",
    "print()\n",
    "print('Source after preprocessing (indices):', X[index])\n",
    "print('Target after preprocessing (indices):', Y[index])\n",
    "print()\n",
    "print('Source after preprocessing (one-hot):', Xoh[index])\n",
    "print('Target after preprocessing (one-hot):', Yoh[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeator = RepeatVector(Tx, name='rep')\n",
    "concatenator = Concatenate(axis=-1, name='conc')\n",
    "densor = Dense(1, activation='relu', name='densor')\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes=1, name='doter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    e = densor(concat)\n",
    "    alphas = activator(e)\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True, name='post_activation')\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(a, s)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        out = output_layer(s)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs, name='TranslationModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 41)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       18944       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rep (RepeatVector)              (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 post_activation[0][0]            \n",
      "                                                                 post_activation[1][0]            \n",
      "                                                                 post_activation[2][0]            \n",
      "                                                                 post_activation[3][0]            \n",
      "                                                                 post_activation[4][0]            \n",
      "                                                                 post_activation[5][0]            \n",
      "                                                                 post_activation[6][0]            \n",
      "                                                                 post_activation[7][0]            \n",
      "                                                                 post_activation[8][0]            \n",
      "                                                                 post_activation[9][0]            \n",
      "                                                                 post_activation[10][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conc (Concatenate)              (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 rep[0][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[1][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[2][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[3][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[4][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[5][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[6][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[7][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[8][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[9][0]                        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[10][0]                       \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 rep[11][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "densor (Dense)                  (None, 30, 1)        129         conc[0][0]                       \n",
      "                                                                 conc[1][0]                       \n",
      "                                                                 conc[2][0]                       \n",
      "                                                                 conc[3][0]                       \n",
      "                                                                 conc[4][0]                       \n",
      "                                                                 conc[5][0]                       \n",
      "                                                                 conc[6][0]                       \n",
      "                                                                 conc[7][0]                       \n",
      "                                                                 conc[8][0]                       \n",
      "                                                                 conc[9][0]                       \n",
      "                                                                 conc[10][0]                      \n",
      "                                                                 conc[11][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           densor[0][0]                     \n",
      "                                                                 densor[1][0]                     \n",
      "                                                                 densor[2][0]                     \n",
      "                                                                 densor[3][0]                     \n",
      "                                                                 densor[4][0]                     \n",
      "                                                                 densor[5][0]                     \n",
      "                                                                 densor[6][0]                     \n",
      "                                                                 densor[7][0]                     \n",
      "                                                                 densor[8][0]                     \n",
      "                                                                 densor[9][0]                     \n",
      "                                                                 densor[10][0]                    \n",
      "                                                                 densor[11][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "doter (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "post_activation (LSTM)          [(None, 64), (None,  33024       doter[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 doter[1][0]                      \n",
      "                                                                 post_activation[0][0]            \n",
      "                                                                 post_activation[0][2]            \n",
      "                                                                 doter[2][0]                      \n",
      "                                                                 post_activation[1][0]            \n",
      "                                                                 post_activation[1][2]            \n",
      "                                                                 doter[3][0]                      \n",
      "                                                                 post_activation[2][0]            \n",
      "                                                                 post_activation[2][2]            \n",
      "                                                                 doter[4][0]                      \n",
      "                                                                 post_activation[3][0]            \n",
      "                                                                 post_activation[3][2]            \n",
      "                                                                 doter[5][0]                      \n",
      "                                                                 post_activation[4][0]            \n",
      "                                                                 post_activation[4][2]            \n",
      "                                                                 doter[6][0]                      \n",
      "                                                                 post_activation[5][0]            \n",
      "                                                                 post_activation[5][2]            \n",
      "                                                                 doter[7][0]                      \n",
      "                                                                 post_activation[6][0]            \n",
      "                                                                 post_activation[6][2]            \n",
      "                                                                 doter[8][0]                      \n",
      "                                                                 post_activation[7][0]            \n",
      "                                                                 post_activation[7][2]            \n",
      "                                                                 doter[9][0]                      \n",
      "                                                                 post_activation[8][0]            \n",
      "                                                                 post_activation[8][2]            \n",
      "                                                                 doter[10][0]                     \n",
      "                                                                 post_activation[9][0]            \n",
      "                                                                 post_activation[9][2]            \n",
      "                                                                 doter[11][0]                     \n",
      "                                                                 post_activation[10][0]           \n",
      "                                                                 post_activation[10][2]           \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 23)           1495        post_activation[0][0]            \n",
      "                                                                 post_activation[1][0]            \n",
      "                                                                 post_activation[2][0]            \n",
      "                                                                 post_activation[3][0]            \n",
      "                                                                 post_activation[4][0]            \n",
      "                                                                 post_activation[5][0]            \n",
      "                                                                 post_activation[6][0]            \n",
      "                                                                 post_activation[7][0]            \n",
      "                                                                 post_activation[8][0]            \n",
      "                                                                 post_activation[9][0]            \n",
      "                                                                 post_activation[10][0]           \n",
      "                                                                 post_activation[11][0]           \n",
      "==================================================================================================\n",
      "Total params: 53,592\n",
      "Trainable params: 53,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 222s 2ms/step - loss: 11.6470 - output_loss: 1.6362 - output_acc: 0.8500 - output_acc_1: 0.7064 - output_acc_2: 0.5384 - output_acc_3: 0.9268 - output_acc_4: 0.7006 - output_acc_5: 0.4375 - output_acc_6: 0.9841 - output_acc_7: 0.4954 - output_acc_8: 0.4333 - output_acc_9: 0.9850 - output_acc_10: 0.4384 - output_acc_11: 0.4001\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 209s 2ms/step - loss: 7.7325 - output_loss: 1.4989 - output_acc: 0.9310 - output_acc_1: 0.8446 - output_acc_2: 0.8452 - output_acc_3: 0.9993 - output_acc_4: 0.8228 - output_acc_5: 0.5498 - output_acc_6: 1.0000 - output_acc_7: 0.6522 - output_acc_8: 0.6093 - output_acc_9: 0.9999 - output_acc_10: 0.5109 - output_acc_11: 0.4673\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 213s 2ms/step - loss: 6.7465 - output_loss: 1.4632 - output_acc: 0.9434 - output_acc_1: 0.8934 - output_acc_2: 0.9134 - output_acc_3: 0.9999 - output_acc_4: 0.8553 - output_acc_5: 0.6161 - output_acc_6: 1.0000 - output_acc_7: 0.6873 - output_acc_8: 0.6692 - output_acc_9: 0.9999 - output_acc_10: 0.5197 - output_acc_11: 0.4788\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 207s 2ms/step - loss: 6.1052 - output_loss: 1.4289 - output_acc: 0.9614 - output_acc_1: 0.9112 - output_acc_2: 0.9414 - output_acc_3: 1.0000 - output_acc_4: 0.8832 - output_acc_5: 0.6733 - output_acc_6: 1.0000 - output_acc_7: 0.7069 - output_acc_8: 0.7074 - output_acc_9: 0.9999 - output_acc_10: 0.5237 - output_acc_11: 0.4819\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 212s 2ms/step - loss: 5.6499 - output_loss: 1.3823 - output_acc: 0.9776 - output_acc_1: 0.9207 - output_acc_2: 0.9490 - output_acc_3: 1.0000 - output_acc_4: 0.9028 - output_acc_5: 0.7115 - output_acc_6: 1.0000 - output_acc_7: 0.7158 - output_acc_8: 0.7364 - output_acc_9: 1.0000 - output_acc_10: 0.5273 - output_acc_11: 0.4905\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 214s 2ms/step - loss: 5.3310 - output_loss: 1.3459 - output_acc: 0.9871 - output_acc_1: 0.9277 - output_acc_2: 0.9563 - output_acc_3: 0.9999 - output_acc_4: 0.9133 - output_acc_5: 0.7394 - output_acc_6: 1.0000 - output_acc_7: 0.7219 - output_acc_8: 0.7516 - output_acc_9: 1.0000 - output_acc_10: 0.5300 - output_acc_11: 0.5004\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 209s 2ms/step - loss: 5.0932 - output_loss: 1.3184 - output_acc: 0.9932 - output_acc_1: 0.9317 - output_acc_2: 0.9611 - output_acc_3: 1.0000 - output_acc_4: 0.9236 - output_acc_5: 0.7634 - output_acc_6: 1.0000 - output_acc_7: 0.7273 - output_acc_8: 0.7617 - output_acc_9: 1.0000 - output_acc_10: 0.5313 - output_acc_11: 0.5090\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 214s 2ms/step - loss: 4.9067 - output_loss: 1.2981 - output_acc: 0.9962 - output_acc_1: 0.9347 - output_acc_2: 0.9634 - output_acc_3: 1.0000 - output_acc_4: 0.9318 - output_acc_5: 0.7834 - output_acc_6: 1.0000 - output_acc_7: 0.7326 - output_acc_8: 0.7703 - output_acc_9: 1.0000 - output_acc_10: 0.5332 - output_acc_11: 0.5162\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 212s 2ms/step - loss: 4.7570 - output_loss: 1.2816 - output_acc: 0.9978 - output_acc_1: 0.9384 - output_acc_2: 0.9662 - output_acc_3: 1.0000 - output_acc_4: 0.9396 - output_acc_5: 0.8002 - output_acc_6: 1.0000 - output_acc_7: 0.7379 - output_acc_8: 0.7763 - output_acc_9: 1.0000 - output_acc_10: 0.5347 - output_acc_11: 0.5216 17s - loss: 4.7650 - output_loss: 1.2819 - output_acc: 0.9978 - output_acc_1: 0.9380 - output_acc_2: 0.9664 - output_acc_3: 1.0000 - output_acc_4: 0.9391 - output_acc_5: 0.7988 - output_acc_6: 1.00\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 211s 2ms/step - loss: 4.6306 - output_loss: 1.2684 - output_acc: 0.9986 - output_acc_1: 0.9429 - output_acc_2: 0.9700 - output_acc_3: 1.0000 - output_acc_4: 0.9452 - output_acc_5: 0.8162 - output_acc_6: 1.0000 - output_acc_7: 0.7436 - output_acc_8: 0.7815 - output_acc_9: 1.0000 - output_acc_10: 0.5368 - output_acc_11: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5d75ff668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human:    明天下午3:04\n",
      "machine:  +3D>14:30:49\n",
      "human:    这周六10:20\n",
      "machine:  TW6>10:00:00\n",
      "human:    上午9点10分\n",
      "machine:  ABS>09:01:11\n",
      "human:    10分钟以后\n",
      "machine:  +10M        \n",
      "human:    下周日下午3点45分\n",
      "machine:  NW7>14:45:04\n",
      "human:    再过3小时\n",
      "machine:  +3H         \n",
      "human:    今天22点08分30秒\n",
      "machine:  +0D>22:08:08\n"
     ]
    }
   ],
   "source": [
    "examples = ['明天下午3:04', '这周六10:20', '上午9点10分', '10分钟以后', \n",
    "            '下周日下午3点45分', '再过3小时', '今天22点08分30秒']    \n",
    "source = np.array([string2int(example, Tx, human_vocab) for example in examples])\n",
    "source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "prediction = model.predict([source, s0, c0])\n",
    "prediction = np.argmax(prediction, axis = -1).transpose()\n",
    "\n",
    "for i in range(len(examples)):\n",
    "    print(\"human:   \", examples[i])\n",
    "    output = [inv_machine_vocab[int(j)] for j in prediction[i]]\n",
    "    print(\"machine: \", ''.join(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
